{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run For the first time\n",
    "!pip install emoji\n",
    "!pip install keras_metrics\n",
    "!pip install keras-self-attention\n",
    "!pip install extra-keras-metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114
    },
    "colab_type": "code",
    "id": "XrRaD0F2xbxm",
    "outputId": "6c169d48-c43c-4e61-cbd8-5c7f4366e40c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import tensorflow_hub as hub\n",
    "import math\n",
    "import pickle\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import emoji\n",
    "import pickle\n",
    "import re\n",
    "import keras_metrics as km\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numpy import random\n",
    "from collections import Counter\n",
    "\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Bidirectional, average, Average, Concatenate\n",
    "from keras.layers import Flatten, BatchNormalization, concatenate, GRU, SpatialDropout1D, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Embedding, Dropout, Conv2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "from keras.layers import Activation\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "nltk.download('punkt')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "J97kjnISyIhf",
    "outputId": "4d068062-5377-4041-f937-355b5c1b228d"
   },
   "outputs": [],
   "source": [
    "''' Uncomment to use in colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x-ibFLJujKJ5"
   },
   "outputs": [],
   "source": [
    "root_path='ROOT_FOLDER/Sentimix/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EXlXZTxEx4SJ"
   },
   "outputs": [],
   "source": [
    "labels_train_raw=pd.read_csv(root_path+'Train_data/labels_train.csv')\n",
    "labels_dev_raw=pd.read_csv(root_path+'Train_data/labels_dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5nkf_mi4DWHB"
   },
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(root_path+'/pure_hinglish_with_hindi_cuss_train.csv')\n",
    "dev_data=pd.read_csv(root_path+'pure_hinglish_with_hindi_cuss_dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "RevbZJRWytz4",
    "outputId": "0704886c-bf07-44cf-b418-771e30a3e1e7"
   },
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "le.fit(labels_train_raw)\n",
    "labels_train_le=le.transform(labels_train_raw)\n",
    "labels_dev_le=le.transform(labels_dev_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GpBF8hRBGC2g"
   },
   "outputs": [],
   "source": [
    "ohc=OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "JBFt7JAjGLN6",
    "outputId": "0606c1b2-1a8f-42f8-efcb-3cc96c598704"
   },
   "outputs": [],
   "source": [
    "ohc=OneHotEncoder()\n",
    "labels_train=ohc.fit_transform(labels_train_le.reshape(-1,1))\n",
    "labels_dev=ohc.transform(labels_dev_le.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "i208B53c7RB4",
    "outputId": "df03a4c9-8005-4bb2-f6db-80fb85c8247d"
   },
   "outputs": [],
   "source": [
    "def remove_pattern(input_txt, pattern,with_space=False):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    if with_space==False:\n",
    "      for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "    else:\n",
    "      for i in r:\n",
    "        input_txt = re.sub(i, ' ', input_txt)\n",
    "    return input_txt \n",
    "def remove_pattern_rep(input_txt, pattern,rep_pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "      input_txt = re.sub(i, rep_pattern, input_txt)\n",
    "\n",
    "    return input_txt \n",
    "\n",
    "with open(root_path+'helper_data/contractions.pkl','rb')as f:\n",
    "  contractions=pickle.load(f)\n",
    "\n",
    "contractions=Counter(contractions)\n",
    "with open(root_path+'helper_data/acronyms.pkl','rb')as f:\n",
    "  acronyms=pickle.load(f)\n",
    "acronyms=Counter(acronyms)\n",
    "def acronym(df,column):\n",
    "  s_l=[]\n",
    "  for i in range(df.shape[0]):\n",
    "    sent=str(df[column][i]).lower()\n",
    "    w_l=[]\n",
    "    for word in sent.split():\n",
    "      if acronyms[word]!=0:\n",
    "        w_l.append(acronyms[word])\n",
    "      else:\n",
    "        w_l.append(word)\n",
    "    s_l.append(' '.join(w_l))\n",
    "  return s_l\n",
    "with open(root_path+'hinglish_to_english.pickle','rb')as f:\n",
    "  hing_to_eng=pickle.load(f)\n",
    "hing_to_eng=Counter(hing_to_eng)\n",
    "def hindi_se_english(df,column):\n",
    "  s_l=[]\n",
    "  for i in range(df.shape[0]):\n",
    "    w_l=[]\n",
    "    sent=str(df[column][i])\n",
    "    for word in sent.split():\n",
    "      if hing_to_eng[word]!=0:\n",
    "        w_l.append(hing_to_eng[word])\n",
    "      else:\n",
    "        w_l.append(word)\n",
    "    s_l.append(' '.join(w_l))\n",
    "  return s_l\n",
    "with open(root_path+'Hinglish_utils/Hinglish_Profanity_dict.pkl', 'rb') as handle:\n",
    "    cuss_dict=pickle.load(handle)\n",
    "cuss_dict=Counter(cuss_dict)\n",
    "cuss_dict['bsdk']='abuse'\n",
    "cuss_dict['bhosadike']='abuse'\n",
    "def replace_cuss(df,column):\n",
    "  s_l=[]\n",
    "  for i in range(df.shape[0]):\n",
    "    sent=str(df[column][i]).lower()\n",
    "    w_l=[]\n",
    "    for word in sent.split():\n",
    "      if cuss_dict[word]!=0:\n",
    "        #w_l.append('abuse')\n",
    "        w_l.append(cuss_dict[word])\n",
    "      else:\n",
    "        w_l.append(word)\n",
    "    s_l.append(' '.join(w_l))\n",
    "  return s_l\n",
    "def remove_contraction(df,column):\n",
    "  s_l=[]\n",
    "  for i in range(df.shape[0]):\n",
    "    sent=str(df[column][i]).lower()\n",
    "    w_l=[]\n",
    "    for word in sent.split():\n",
    "      if contractions[word]!=0:\n",
    "        w_l.append(contractions[word])\n",
    "      else:\n",
    "        w_l.append(word)\n",
    "    s_l.append(' '.join(w_l))\n",
    "  return s_l\n",
    "def cleaning(data_f,cleaning_col,new_col):\n",
    "  for i in range(data_f.shape[0]):\n",
    "    data_f[cleaning_col][i]=emoji.demojize(str(data_f[cleaning_col][i]))\n",
    "  data_f[new_col]=replace_cuss(data_f,cleaning_col)\n",
    "  data_f[new_col]=np.vectorize(remove_pattern)(data_f[new_col],\"_\",with_space=True)\n",
    "  data_f[new_col]=np.vectorize(remove_pattern)(data_f[new_col],\"-\",with_space=True)\n",
    "  data_f[new_col]=np.vectorize(remove_pattern)(data_f[new_col],\":\",with_space=True)\n",
    "  data_f[new_col] = np.vectorize(remove_pattern_rep)(data_f[new_col], \"@ [\\w]*\",\"<USR>\")\n",
    "  data_f[new_col] = np.vectorize(remove_pattern_rep)(data_f[new_col], \"[0-9]+\",\"<NUM>\")\n",
    "  data_f[new_col]=hindi_se_english(data_f,new_col)\n",
    "  data_f[new_col]=remove_contraction(data_f,new_col)\n",
    "  data_f[new_col]=acronym(data_f,new_col)\n",
    "  data_f[new_col]=data_f[new_col].str.replace(\"[^a-zA-Z]<>\", \" \")\n",
    "  data_f[new_col] = np.vectorize(remove_pattern)(data_f[new_col], \"~\",with_space=False)\n",
    "  data_f[new_col] = np.vectorize(remove_pattern)(data_f[new_col], \"!\",with_space=True)\n",
    "  data_f[new_col] = np.vectorize(remove_pattern)(data_f[new_col], \".\",with_space=True)\n",
    "  data_f[new_col] = data_f[new_col].apply(lambda x: ' '.join([w for w in x.split() if len(w)>1]))\n",
    "  return data_f\n",
    "import numpy as np\n",
    "a=cleaning(train_data,'sent','hindi_clean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_WnA7MhAFH8f"
   },
   "outputs": [],
   "source": [
    "b=cleaning(dev_data,'sent','hindi_clean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iQPNNhjf4Tjo"
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eUimeWjPzXTB"
   },
   "outputs": [],
   "source": [
    "max_len = 25\n",
    "tok = Tokenizer()\n",
    "tok.fit_on_texts(a['hindi_clean'].astype(str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ovf7C-iX1T-S"
   },
   "outputs": [],
   "source": [
    "sequences_dev = tok.texts_to_sequences(b['hindi_clean'].astype(str))\n",
    "vocab_size = len(tok.word_index) + 1\n",
    "sequences_matrix_dev = sequence.pad_sequences(sequences_dev,maxlen=max_len,padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "YtrwEi0hGdEv",
    "outputId": "1350a99a-7f48-45a0-d6a4-96d9b9773f79"
   },
   "outputs": [],
   "source": [
    "\n",
    "def custom_gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'custom_gelu': Activation(custom_gelu)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Ns59EE9a4cm"
   },
   "source": [
    "## abuse feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sEyWVVJua9RG"
   },
   "outputs": [],
   "source": [
    "abuse_f=np.zeros((train_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WqTkqE2WbLxo"
   },
   "outputs": [],
   "source": [
    "for i in range(train_data.shape[0]):\n",
    "  sent=str(a['hindi_clean'][i])\n",
    "  for word in sent.split():\n",
    "    if cuss_dict[word]!=0:\n",
    "      abuse_f[i]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "elHgHogVbu6g"
   },
   "outputs": [],
   "source": [
    "abuse_fd=np.zeros((dev_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "elHGVB0Tb25H"
   },
   "outputs": [],
   "source": [
    "for i in range(dev_data.shape[0]):\n",
    "  sent=str(b['hindi_clean'][i])\n",
    "  for word in sent.split():\n",
    "    if cuss_dict[word]!=0:\n",
    "      abuse_fd[i]+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hgIw3Ac7QlIs"
   },
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m3NhuXrxQnnd"
   },
   "outputs": [],
   "source": [
    "def cnn():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(vocab_size,100,input_length=max_len)(inputs)\n",
    "    x = Conv1D(256, 3, activation='relu')(layer)\n",
    "    x = MaxPooling1D(3)(x)\n",
    "\n",
    "    x = Conv1D(128, 4, activation='relu')(x)\n",
    "    x = LSTM(100,recurrent_dropout=0.2)(x)\n",
    "    layer = Dense(200,name='FC1')(x)\n",
    "    layer = BatchNormalization(name = 'BN1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.4)(layer)\n",
    "    layer = Dense(300,name='FC2')(layer)\n",
    "    layer = BatchNormalization(name = 'BN2')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.4)(layer)\n",
    "    layer = Dense(3,name='out_layer')(layer)\n",
    "    layer = BatchNormalization(name = 'BN4')(layer)\n",
    "    layer = Activation('softmax')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "XiKUapNZRPJ6",
    "outputId": "6ea5221c-d6cd-4c76-877a-7763ab0cb793"
   },
   "outputs": [],
   "source": [
    "model=cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "mO3wV1XmRsXf",
    "outputId": "48d82c70-5e82-4772-f34b-276eea65eab2"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "3L3oTMaIRvPt",
    "outputId": "47a6b78e-3fb9-4766-cf54-b28dbf846213"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "colab_type": "code",
    "id": "UmlQVM41Rz9c",
    "outputId": "91144b2f-1eca-4a51-ee90-605d52d82b34"
   },
   "outputs": [],
   "source": [
    "model.fit(sequences_matrix_train,labels_train,validation_data=(sequences_matrix_dev,labels_dev),epochs=5,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "19RCFKzmVEjV"
   },
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7XUIw8gV1kVf"
   },
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,200,input_length=max_len)(inputs)\n",
    "    layer = LSTM(100,recurrent_dropout=0.2)(layer)\n",
    "    layer = Dense(200,name='FC1')(layer)\n",
    "    layer = BatchNormalization(name = 'BN1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.4)(layer)\n",
    "    layer = Dense(300,name='FC2')(layer)\n",
    "    layer = BatchNormalization(name = 'BN2')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.4)(layer)\n",
    "    layer = Dense(3,name='out_layer')(layer)\n",
    "    layer = BatchNormalization(name = 'BN4')(layer)\n",
    "    layer = Activation('softmax')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "RVpUE7WF2DlK",
    "outputId": "54baa8d1-76dd-4514-f7d5-053816d7ff5d"
   },
   "outputs": [],
   "source": [
    "model=RNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "3_Iaqkdq2Hp2",
    "outputId": "71b57ca6-9d8e-4dd3-9065-aac531ba544c"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "Sv1Bgpe-lgL_",
    "outputId": "0383b424-bbe4-409f-d12d-ea8c1f07f282"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 836
    },
    "colab_type": "code",
    "id": "uFYgtVM82dTM",
    "outputId": "84d6fd2b-57d8-43b9-bdaf-eb2c09b3b3b8"
   },
   "outputs": [],
   "source": [
    "model.fit(sequences_matrix_train,labels_train,validation_data=(sequences_matrix_dev,labels_dev),epochs=5,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-vDWgpzeGcYn"
   },
   "source": [
    "## combining train and dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZIfVwivzG2YN"
   },
   "outputs": [],
   "source": [
    "new_mat=np.concatenate((sequences_matrix_train,sequences_matrix_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ft6HkMAgHC8j",
    "outputId": "69dc052c-1334-4f08-dec0-e6108741563e"
   },
   "outputs": [],
   "source": [
    "new_label=np.concatenate((np.array(labels_train),np.array(labels_dev)),axis=0)\n",
    "print(new_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "YPAEtREPIkw8",
    "outputId": "245cf7f0-5fd7-40ba-a8bf-21d2660e2b01"
   },
   "outputs": [],
   "source": [
    "ohc=OneHotEncoder()\n",
    "new_label=ohc.fit_transform(new_label.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NBZFaFumIr_3",
    "outputId": "2f2bba50-aa7a-4e71-c72d-1259cf3982ae"
   },
   "outputs": [],
   "source": [
    "new_abuse=np.concatenate((abuse_f,abuse_fd))\n",
    "print(new_abuse.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HwO3GQbp1V6l"
   },
   "source": [
    "## Attention Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "J5EV-8QQ8SHP",
    "outputId": "890efa1b-80a1-453c-b6be-4f31fbd5ac6c"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "model_emb_300 = gensim.models.Word2Vec.load(\"/content/drive/My Drive/Sentimix/hinglish_word2vec_embeddings_300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tW6uIhyVdgfO"
   },
   "outputs": [],
   "source": [
    "word_index=tok.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q5GP5jtJdflQ"
   },
   "outputs": [],
   "source": [
    "# embedding_matrix_1 = np.zeros((len(tok.word_index) + 1, 100))\n",
    "# for word, i in tok.word_index.items():\n",
    "#     if word in model_emb_100.wv.vocab:\n",
    "#       embedding_matrix_1[i] = model_emb_100[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mgn4w8FhEqXw"
   },
   "outputs": [],
   "source": [
    "# embedding_matrix_2 = np.zeros((len(tok.word_index) + 1, 200))\n",
    "# for word, i in tok.word_index.items():\n",
    "#     if word in model_emb_200.wv.vocab:\n",
    "#       embedding_matrix_2[i] = model_emb_200[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Hb0EV4g2EqKw",
    "outputId": "cc412bd6-6536-487c-9490-8e3764ade1e8"
   },
   "outputs": [],
   "source": [
    "embedding_matrix_3 = np.zeros((len(tok.word_index) + 1, 300))\n",
    "for word, i in tok.word_index.items():\n",
    "    if word in model_emb_300.wv.vocab:\n",
    "      embedding_matrix_3[i] = model_emb_300[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6q_LOMuBOKYD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "class Metrics(Callback):\n",
    "  def on_train_begin(self, logs={}):\n",
    "    self.val_f1s = []\n",
    "    self.val_recalls = []\n",
    "    self.val_precisions = []\n",
    "  \n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    val_predict = (np.asarray(self.model.predict([self.validation_data[0]])))\n",
    "    val_targ = self.validation_data[1]\n",
    "    val_predict=val_predict.argmax(axis=-1)\n",
    "    \n",
    "    val_targ=val_targ.argmax(axis=-1)\n",
    "    \n",
    "    _val_f1 = f1_score(val_targ, val_predict,average='macro')\n",
    "    _val_recall = recall_score(val_targ, val_predict,average='macro')\n",
    "    _val_precision = precision_score(val_targ, val_predict,average='macro')\n",
    "    self.val_f1s.append(_val_f1)\n",
    "    self.val_recalls.append(_val_recall)\n",
    "    self.val_precisions.append(_val_precision)\n",
    "    print(\" — val_f1: %f — val_precision: %f — val_recall %f\" %(_val_f1, _val_precision, _val_recall))\n",
    "    return\n",
    " \n",
    "f1_metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9AJPD4XQEc9-"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NRUGtTlKEMta"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.layers import CuDNNGRU,CuDNNLSTM,GlobalMaxPool1D,GlobalAveragePooling1D\n",
    "class Attention(Layer):\n",
    "    def __init__(self,step_dim=20,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input,CuDNNLSTM,CuDNNGRU\n",
    "from keras.layers import LSTM, Bidirectional, Dropout\n",
    "\n",
    "\n",
    "def BidLstm(maxlen, max_features, embed_size):\n",
    "    inp1 = Input(shape=(maxlen, ))\n",
    "    #inp2=Input(shape=(1,))\n",
    "    x=Embedding(len(tok.word_index)+1,embed_size)(inp1)\n",
    "    #x = Embedding(len(tok.word_index) + 1,embed_size,weights=[embedding_matrix_3],\n",
    "    #                trainable=True)(inp1)\n",
    "    # x2 = Embedding(len(tok.word_index) + 1,embed_size_2,weights=[embedding_matrix_2],\n",
    "    #                trainable=True)(inp1)\n",
    "    # x3 = Embedding(len(tok.word_index) + 1,embed_size_3,weights=[embedding_matrix_3],\n",
    "    #                trainable=True)(inp1)\n",
    "    # x1 = Bidirectional(LSTM(200, return_sequences=True, dropout=0.4,\n",
    "    #                        recurrent_dropout=0.4))(x1)\n",
    "    # x2 = Bidirectional(LSTM(200, return_sequences=True, dropout=0.4,\n",
    "    #                        recurrent_dropout=0.4))(x2)\n",
    "    # x3 = Bidirectional(LSTM(200, return_sequences=True, dropout=0.4,\n",
    "    #                        recurrent_dropout=0.4))(x3)   \n",
    "    #x = Attention(maxlen)(x)\n",
    "    # x2 = Attention(maxlen)(x2)\n",
    "    # x3 = Attention(maxlen)(x3)\n",
    "    # x=  Concatenate()([x1,x2,x3])\n",
    "    x=SpatialDropout1D(0.1)(x)\n",
    "    x = Bidirectional(CuDNNLSTM(100, return_sequences=True))(x)\n",
    "    x = SeqSelfAttention(kernel_regularizer=keras.regularizers.l2(1e-4),\n",
    "                       bias_regularizer=keras.regularizers.l1(1e-4),\n",
    "                       attention_regularizer_weight=1e-4,\n",
    "                       name='Attention')(x) \n",
    "    #x = Attention(maxlen)(x)\n",
    "    # layer = Dense(600,name='FC1')(x)\n",
    "    # layer = Dense(300,activation='relu')(layer)\n",
    "    # layer = Dense(200,activation='relu')(layer)\n",
    " #   layer = BatchNormalization(name = 'BN1')(layer)\n",
    "    # layer = Activation('relu')(layer)\n",
    "    # layer = Dropout(0.4)(layer)\n",
    "    x2=GlobalMaxPool1D()(x)\n",
    "    x3=GlobalAveragePooling1D()(x)\n",
    "    x=  Concatenate()([x2,x3])\n",
    "    layer = Dense(128,name='FC2')(x)\n",
    "#    layer = BatchNormalization(name = 'BN2')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "   # layer=  Concatenate()([layer,inp2])\n",
    "    # layer=Dense(256,activation='relu')(layer)\n",
    "    # layer=Dense(128,activation='relu')(layer)\n",
    "    layer = Dense(3,name='out_layer',activation='softmax')(layer)\n",
    "\n",
    "    model = Model(inputs=[inp1],outputs=layer)\n",
    "\n",
    "    return model\n",
    "model=BidLstm(max_len,max_features=len(tok.word_index)+1,embed_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1uITF0D84Atv"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['acc',km.f1_score()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "id": "d2DGEX_P5qWJ",
    "outputId": "aa6580f0-892d-429b-a5e4-b82e02cae3de"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bPswR_f7RF-w"
   },
   "outputs": [],
   "source": [
    "cp_filepath=root_path+'/checkpoints/bilstm_self_attention.h5'\n",
    "cp_check_point=keras.callbacks.ModelCheckpoint(cp_filepath, monitor='val_f1_score', verbose=0, save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
    "es = EarlyStopping(monitor='val_f1_score', mode='max', min_delta=0,patience=5,restore_best_weights=True)\n",
    "reduce_lr=keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "b-aKbqPo4Q2R",
    "outputId": "7a67c9eb-1ad3-40b6-a76c-465d13324033"
   },
   "outputs": [],
   "source": [
    "model.fit([sequences_matrix_train],labels_train,validation_data=([sequences_matrix_dev],labels_dev),epochs=10,batch_size=32,callbacks=[es,cp_check_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "9epzi9CSLzYY",
    "outputId": "00053b3e-037f-4a80-951d-96b0e60939bc"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict([sequences_matrix_dev], batch_size=32, verbose=1)\n",
    "\n",
    "print(classification_report(labels_dev_le, np.argmax(y_pred,axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kxihkdmI0_YA"
   },
   "outputs": [],
   "source": [
    "s=b['hindi_clean']\n",
    "sequence_test = tok.texts_to_sequences(s)\n",
    "sequence_test_mat = sequence.pad_sequences(sequence_test,maxlen=max_len,padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rXjh5V9o45tF"
   },
   "outputs": [],
   "source": [
    "preds_dev=model.predict([sequences_matrix_dev,abuse_fd]).argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H3BuNKELAlaC"
   },
   "outputs": [],
   "source": [
    "cuss_dict['bsdk']='abuse'\n",
    "cuss_dict['bhosadike']='abuse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BvlKGAc-5Fi6",
    "outputId": "de3e7499-f20f-4332-85c6-87c7e97a0e4b"
   },
   "outputs": [],
   "source": [
    "for i in range(b.shape[0]):\n",
    "  if le.inverse_transform([preds_dev[i]])[0]!=labels_dev_raw['labels'][i]:\n",
    "    print(b['hindi_clean'][i],le.inverse_transform([preds_dev[i]])[0],labels_dev_raw['labels'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8XO5_7eRsWCM"
   },
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CzueEYFYsvSm"
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "xcotmMbRscCB",
    "outputId": "b0ca591c-8c02-4a90-9dab-4014579b4ab7"
   },
   "outputs": [],
   "source": [
    "\n",
    "with open(\"/content/drive/My Drive/Sentimix/Abhishek Folder/transfer_model.json\") as json_file:\n",
    "  model = model_from_json(json_file.read(),custom_objects={'Attention': Attention})\n",
    "  model.load_weights(\"/content/drive/My Drive/Sentimix/Abhishek Folder/transfer_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "id": "MvZOUt8ksb-l",
    "outputId": "3106f803-9197-46c7-f78b-ea8e1b3a03c7"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "crlCu8MZwqzr",
    "outputId": "e83fbc2c-ca70-49a0-82cf-8c59296a1631"
   },
   "outputs": [],
   "source": [
    "for layer in model.layers[:-3]:\n",
    "    layer.trainable = False\n",
    " \n",
    "# Check the trainable status of the individual layers\n",
    "for layer in model.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5QjNhdD6yIk0",
    "outputId": "d6823688-9ccd-477c-af08-110cf060324c"
   },
   "outputs": [],
   "source": [
    "model.layers[5].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZabYyjKYxkjD"
   },
   "outputs": [],
   "source": [
    "layer = model.layers[5].output\n",
    "layer = Dense(32,activation=custom_gelu)(layer)\n",
    "layer = Dense(64,activation=custom_gelu)(layer)\n",
    "layer = Dense(3,activation=\"softmax\")(layer)\n",
    "\n",
    "new_model = Model(inputs=model.input,outputs=layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "id": "07YxaooIx7PT",
    "outputId": "c8b0b8b1-7a5f-4c39-8be1-709aac81784f"
   },
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMuJ6pDveqoT"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "U0_T9BRiyTHm",
    "outputId": "7d94415b-2454-4832-d9cc-4043417b7506"
   },
   "outputs": [],
   "source": [
    "new_model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['acc',f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "colab_type": "code",
    "id": "kfTCaWmPycnV",
    "outputId": "b64c71af-cbec-4113-f12d-1ff092ff85f6"
   },
   "outputs": [],
   "source": [
    "new_model.fit(sequences_matrix_train,labels_train,validation_data=(sequences_matrix_dev,labels_dev),epochs=5,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "lcTBI8_eOHa9",
    "outputId": "3ee609e6-fe69-4ea3-cbfd-d589260bda8a"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "     'This is the first document.',\n",
    "     'This document is the second document.',\n",
    "     'And this is the third one.',\n",
    "     'Is this the first document?' ]\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8txIk5lLMk7r"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer =TfidfVectorizer(max_features=10000, lowercase=True, analyzer='word',\n",
    "                        stop_words= 'english',ngram_range=(1,2),dtype=np.float32,max_df=0.3,min_df=2)\n",
    "vectorizer.fit(a['hindi_clean'].astype(str))\n",
    "x_train=vectorizer.transform(a['hindi_clean'].astype(str))\n",
    "x_dev=vectorizer.transform(b['hindi_clean'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9_do3YUBDbPU",
    "outputId": "f3cbec56-2171-465d-a930-0f2fcbe6cf3a"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(a['hindi_clean'])\n",
    "X_dev_counts=count_vect.transform(b['hindi_clean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B6AelA3LGv5E"
   },
   "outputs": [],
   "source": [
    "vectorizer_char =TfidfVectorizer(max_features=20000, lowercase=True, analyzer='char',ngram_range=(1,5),dtype=np.float32,max_df=0.5,min_df=8)\n",
    "vectorizer_char.fit(a['hindi_clean'].astype(str))\n",
    "x_train_char=vectorizer_char.transform(a['hindi_clean'].astype(str))\n",
    "x_dev_char=vectorizer_char.transform(b['hindi_clean'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E87-0P29RuUW"
   },
   "source": [
    "## PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OSka17RQRxnn"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ipNC2aAcR2W4"
   },
   "outputs": [],
   "source": [
    "pca_transformer=PCA(n_components=1000)\n",
    "x_train_pca=pca_transformer.fit_transform(x_train.toarray())\n",
    "x_dev_pca=pca_transformer.transform(x_dev.toarray())\n",
    "#x_test_pca=pca_transformer.transform(x_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "8_YCj9SLR4uV",
    "outputId": "9bb6f4a5-4c12-4ccc-c07c-01871c6074f4"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "tsne=TruncatedSVD(n_components=1000)\n",
    "x_train_sne=tsne.fit_transform(x_train.toarray())\n",
    "x_dev_sne=tsne.transform(x_dev.toarray())\n",
    "#x_test_sne=tsne.transform(x_test.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cEPL2rpVDoiI"
   },
   "source": [
    "## BaseLine Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "9pGDBOTNEE0H",
    "outputId": "fcc1186c-0d35-491b-88e4-c238d9be6921"
   },
   "outputs": [],
   "source": [
    "le_x=LabelEncoder()\n",
    "label_train_le=le_x.fit_transform(labels_train_raw)\n",
    "label_dev_le=le_x.fit_transform(labels_dev_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aTmG19G8EQQ7"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "piJyBxhWDn9y",
    "outputId": "dc99b778-ce35-476c-ceac-d16158dbe537"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit((X_train_counts), label_train_le)\n",
    "y_preds=clf.predict(X_dev_counts)\n",
    "f1_score(label_dev_le,y_preds,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zXVjMZ1nERxf",
    "outputId": "96c08c0d-485f-4596-b3cb-0cb1e27c52b2"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf=SGDClassifier().fit(x_train_pca,labels_train_le)\n",
    "y_preds=sgd_clf.predict(x_dev_pca)\n",
    "f1_score(labels_dev_le,y_preds,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "N46Gh4hqEVm5",
    "outputId": "a03b5c2d-334a-480d-df84-6bf49090af74"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf_svc=SVC(gamma='scale',decision_function_shape='ovo',kernel='rbf').fit(x_train_pca,labels_train_le)\n",
    "y_preds=clf_svc.predict(x_dev_pca)\n",
    "f1_score(labels_dev_le,y_preds,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OYFGmW3JRRQr",
    "outputId": "a7291eb6-ac77-4816-e810-18700d9b55f9"
   },
   "outputs": [],
   "source": [
    "f1_score(labels_dev_le,y_preds,average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ch2-uxq3JAzT"
   },
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g146XX7vIqgL"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bO1JQZJqJKhr"
   },
   "outputs": [],
   "source": [
    "xgb_params = {'learning_rate': 0.05, \n",
    "              'max_depth': 4,\n",
    "              'subsample': 0.9,        \n",
    "              'colsample_bytree': 0.9,\n",
    "              'objective': 'binary:logistic',\n",
    "              'silent': 1, \n",
    "              'n_estimators':500, \n",
    "              'gamma':1,         \n",
    "              'min_child_weight':4}   \n",
    "clf = xgb.XGBClassifier(**xgb_params, seed = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q0p0Iuq0Jtdt"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "cZKabB6bJ0c6",
    "outputId": "a4559b46-591f-4ccd-905d-5edf50ed1e7f"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42)\n",
    "results = cross_val_score(clf, x_train_char, labels_train, cv=skf)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gPDClRuPMBPL",
    "outputId": "a2a0e65d-02ee-4ca1-8f25-65cbf5fb0016"
   },
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pD7xa2bHMEmD"
   },
   "outputs": [],
   "source": [
    "clf.fit(x_train_char,labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "87EUsjsMOp4f"
   },
   "outputs": [],
   "source": [
    "y_preds=clf.predict(x_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VofuLf-mPoEK",
    "outputId": "d077af50-a422-4d5c-9c00-19e0d10206df"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(labels_dev,y_preds,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JWQHilD46LMV"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42)\n",
    "for train_index, test_index in skf.split(X,y): \n",
    "    X_train, X_test = x_train[train_index], x_train[val_index] \n",
    "    y_train, y_test = labels_train_raw[train_index], labels_train_raw[val_index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Xk1sFmJdNDtM",
    "outputId": "b8f0ac10-ef83-4d66-a5c1-5cf1b1b22ed6"
   },
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iFLK7TntNQu7",
    "outputId": "d015c2cc-ad07-4181-b2fe-a5de619e6043"
   },
   "outputs": [],
   "source": [
    "x_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uwaA6_OrQIEE",
    "outputId": "642b398b-9bc3-4792-ddad-132b9450a484"
   },
   "outputs": [],
   "source": [
    "preds_test = clf.predict(x_dev)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(labels_dev, preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jgdEL4rPRsA0"
   },
   "outputs": [],
   "source": [
    "# dsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l--tDqjBUIC2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qYGQHtUiAjg8"
   },
   "source": [
    "## Text Blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LN8_t0IaApoo"
   },
   "outputs": [],
   "source": [
    "import textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-QJRqSvFArbS"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T_h9OL5qBDOd"
   },
   "outputs": [],
   "source": [
    "blob = TextBlob(train_data['tidy_tweet_abuse_1'][19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "dIa1Kc21DGpB",
    "outputId": "ad3da0a3-e068-4969-b61f-dddc51774f9f"
   },
   "outputs": [],
   "source": [
    "train_data['tidy_tweet_abuse_1'][10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "n_Lq5Ij2Coyx",
    "outputId": "53535278-9229-42b8-89b9-be119fa94a46"
   },
   "outputs": [],
   "source": [
    "print(blob.sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3tXXK8qWydSV"
   },
   "source": [
    "## Charcter level LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1rrPbMNq7qtc"
   },
   "source": [
    "### charcter tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E2mXwb8oCaet"
   },
   "outputs": [],
   "source": [
    "max_words = 15000\n",
    "max_len = 20\n",
    "tok_char = Tokenizer(\n",
    "    char_level=True,\n",
    "    filters=None,\n",
    "    lower=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0qNwvTdZycUA"
   },
   "outputs": [],
   "source": [
    "sequences_train_char = tok.texts_to_sequences(a['hindi_clean'].astype(str))\n",
    "vocab_size = len(tok.word_index) + 1\n",
    "sequences_matrix_train_char = sequence.pad_sequences(sequences_train_char,maxlen=110,padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1JSP-_PE8CeM"
   },
   "outputs": [],
   "source": [
    "sequences_dev_char = tok.texts_to_sequences(b['hindi_clean'].astype(str))\n",
    "vocab_size = len(tok.word_index) + 1\n",
    "sequences_matrix_dev_char = sequence.pad_sequences(sequences_dev_char,maxlen=110,padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j6ei-j2h8HOj"
   },
   "outputs": [],
   "source": [
    "model=BidLstm(110,max_features=max_words,embed_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2P5c7xQx8mL7"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "yReGh0HB8pOS",
    "outputId": "ab33cef4-869d-4c3e-ce0a-1bc98993fbfd"
   },
   "outputs": [],
   "source": [
    "model.fit([sequences_matrix_train_char],labels_train,validation_data=([sequences_matrix_dev_char],labels_dev),epochs=5,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A1yMF1G2gpWu"
   },
   "source": [
    "## Read HOT Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DISXSg-08vUg"
   },
   "outputs": [],
   "source": [
    "file_hot=open(root_path+'/Hot_dataset/HOT_Dataset_modified.csv','r') \n",
    "hot_lines=file_hot.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BfJglI0Yk0CC"
   },
   "outputs": [],
   "source": [
    "labels_hot=[]\n",
    "sent_hot=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k3y-aUZtj9bp"
   },
   "outputs": [],
   "source": [
    "for hot_line in hot_lines:\n",
    "  if not hot_line:\n",
    "    continue\n",
    "  else:\n",
    "    try:\n",
    "      labels_hot.append(int(hot_line[0]))\n",
    "      sent_hot.append(hot_line[2:])\n",
    "    except:\n",
    "      continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "aPShs-FElJNB",
    "outputId": "a62941d8-6017-47af-f2af-45885ed94ece"
   },
   "outputs": [],
   "source": [
    "print(len(labels_hot))\n",
    "print(len(sent_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XjHl0FnWgoSM"
   },
   "outputs": [],
   "source": [
    "hot_raw=pd.DataFrame({'sent':sent_hot,'labels':labels_hot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eD8USXcbg-lC"
   },
   "outputs": [],
   "source": [
    "hot_raw.to_csv(root_path+'/Hot_dataset/hot_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "svRzkV5ytN8F"
   },
   "source": [
    "## Modelling hot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lCPHxRLGiMjP"
   },
   "outputs": [],
   "source": [
    "hot_raw=pd.read_csv(root_path+'/Hot_dataset/hot_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GziBpfJStTD5"
   },
   "outputs": [],
   "source": [
    "def cleaning_hot(data_f,cleaning_col,new_col):\n",
    "  for i in range(data_f.shape[0]):\n",
    "    data_f[cleaning_col][i]=emoji.demojize(str(data_f[cleaning_col][i]))\n",
    "  data_f[new_col]=replace_cuss(data_f,cleaning_col)\n",
    "  data_f[new_col]=np.vectorize(remove_pattern)(data_f[new_col],\"_\",with_space=True)\n",
    "  data_f[new_col]=np.vectorize(remove_pattern)(data_f[new_col],\"-\",with_space=True)\n",
    "  data_f[new_col]=np.vectorize(remove_pattern)(data_f[new_col],\":\",with_space=True)\n",
    "  data_f[new_col] = np.vectorize(remove_pattern_rep)(data_f[new_col], \"@[\\w]*\",\"<USR>\")\n",
    "  data_f[new_col] = np.vectorize(remove_pattern_rep)(data_f[new_col], \"http\\S+\",\"<URL>\")\n",
    "  data_f[new_col] = np.vectorize(remove_pattern_rep)(data_f[new_col], \"[0-9]+\",\"<NUM>\")\n",
    "  data_f[new_col]=hindi_se_english(data_f,new_col)\n",
    "  data_f[new_col]=remove_contraction(data_f,new_col)\n",
    "  data_f[new_col]=acronym(data_f,new_col)\n",
    "  data_f[new_col]=data_f[new_col].str.replace(\"[^a-zA-Z]<>\", \" \")\n",
    "  data_f[new_col] = np.vectorize(remove_pattern)(data_f[new_col], \"~\",with_space=False)\n",
    "  #data_f[new_col] = np.vectorize(remove_pattern)(data_f[new_col], \"!\",with_space=True)\n",
    "  #data_f[new_col] = np.vectorize(remove_pattern)(data_f[new_col], \".\",with_space=True)\n",
    "  data_f[new_col] = data_f[new_col].apply(lambda x: ' '.join([w for w in x.split() if len(w)>2]))\n",
    "  return data_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "l_EM1T5Ou_0n",
    "outputId": "a0ed6b30-699a-4e0b-cfca-9faa6fe4f8cd"
   },
   "outputs": [],
   "source": [
    "hot_clean=cleaning_hot(hot_raw,'sent','clean_col')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "CKnbjhAgvI2T",
    "outputId": "59fd9e73-6976-4ca4-bd4d-ff73d38e789c"
   },
   "outputs": [],
   "source": [
    "hot_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cO2ostf8vLe6",
    "outputId": "4ea3b892-b8a6-4c6d-cbbf-7127a17890fd"
   },
   "outputs": [],
   "source": [
    "sum(hot_clean['labels']==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "ER0ddopUwUXN",
    "outputId": "c452ba3b-b705-4536-ffb0-3bf1b9f70920"
   },
   "outputs": [],
   "source": [
    "ohc_hot=OneHotEncoder()\n",
    "hot_labels=ohc_hot.fit_transform(np.array(list(hot_clean['labels'])).reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "G5yZJRZJwqQP",
    "outputId": "a548dd6f-784a-4ec8-9866-7416a97f3ecf"
   },
   "outputs": [],
   "source": [
    "hot_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nzGQ8_-sw7KA"
   },
   "outputs": [],
   "source": [
    "max_words = 15000\n",
    "max_len = 20\n",
    "tok_hot = Tokenizer()\n",
    "tok_hot.fit_on_texts(hot_clean['clean_col'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S8yLCfC7xKy_"
   },
   "outputs": [],
   "source": [
    "sequences_train_hot = tok_hot.texts_to_sequences(hot_clean['clean_col'].astype(str))\n",
    "vocab_size_hot = len(tok_hot.word_index) + 1\n",
    "sequences_matrix_train_hot = sequence.pad_sequences(sequences_train_hot,maxlen=max_len,padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "05yoKJuWjGmR",
    "outputId": "2330a75f-cab4-47e3-a380-e09491dda547"
   },
   "outputs": [],
   "source": [
    "model=Sequential()  \n",
    "\n",
    "# EMBEDDING LAYER - DISTRIBUTED REPRESENTATION OF TWEETS \n",
    "# EMBEDDINGS - GLOVE 100 dimensions further trained on davidson and heot dataset after proper preprocessing\n",
    "\n",
    "# EMBEDDING DIMENSION = 100\n",
    "model.add(Embedding(vocab_size_hot, 300,weights=[embedding_matrix_3], input_length=20, name='embedding_layer'))\n",
    "\n",
    "# Dropout Layer to reduce overfitting \n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# LSTM Layer (2 LSTM layers preferable) - Units : 64\n",
    "model.add(LSTM(64,dropout_W=0.2,dropout_U=0.2))\n",
    "\n",
    "#Series of dense layers  \n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax',name='last'))\n",
    "\n",
    "# Compiling Model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "YfbMUCkVxd2E",
    "outputId": "aad612b3-b11d-4c02-955c-aef594d229fa"
   },
   "outputs": [],
   "source": [
    "model.fit([sequences_matrix_train_hot],hot_labels,validation_split=0.5,epochs=20,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8EkZANXexw_S"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer =TfidfVectorizer(max_features=10000, lowercase=True, analyzer='word',\n",
    "                        stop_words= 'english',ngram_range=(1,2),dtype=np.float32,max_df=0.3,min_df=2)\n",
    "vectorizer.fit(hot_clean['clean_col'].astype(str))\n",
    "x_train_hot=vectorizer.transform(hot_clean['clean_col'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GCPROc-bkSb_"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ug8McytHkMUW"
   },
   "outputs": [],
   "source": [
    "pca_transformer=PCA(n_components=1000)\n",
    "x_train_pca=pca_transformer.fit_transform(x_train_hot.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Cxoitc_mtfY"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bbkPNZLpkQza",
    "outputId": "826ae36d-4262-4733-8619-edff094fe51d"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf_svc=SVC(gamma='scale',decision_function_shape='ovo',kernel='rbf').fit(x_train_pca,hot_clean['labels'])\n",
    "y_preds=clf_svc.predict(x_train_pca)\n",
    "f1_score(hot_clean['labels'],y_preds,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "aHRggKyPmmCE",
    "outputId": "0abd781d-2ade-4751-82f2-6cf8886ae111"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "model_emb_300 = gensim.models.Word2Vec.load(\"/content/drive/My Drive/Sentimix/hinglish_word2vec_embeddings_300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ooDF5nNTp36Y",
    "outputId": "13500d35-e8c7-4c79-8dbc-866e857a4b90"
   },
   "outputs": [],
   "source": [
    "embedding_matrix_3 = np.zeros((len(tok_hot.word_index) + 1, 300))\n",
    "for word, i in tok_hot.word_index.items():\n",
    "    if word in model_emb_300.wv.vocab:\n",
    "      embedding_matrix_3[i] = model_emb_300[word]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "hgIw3Ac7QlIs",
    "19RCFKzmVEjV",
    "-vDWgpzeGcYn",
    "8XO5_7eRsWCM",
    "Ch2-uxq3JAzT",
    "qYGQHtUiAjg8",
    "1rrPbMNq7qtc",
    "A1yMF1G2gpWu",
    "svRzkV5ytN8F"
   ],
   "name": "train_bilstm_attention.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
